{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72462832, 0.57361392, 0.36783573])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1 / (1 + np.exp(-z)) \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054723641712777"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) = \\Sigma{y_i\\log(p_i) + (1 - y_i)\\log(1 - p_i)}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters)\n",
    "    loss = -(y * np.log(p) + (1-y) * np.log(1-p))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = dot_product(X, parameters)\n",
    "    loss = np.power((y_hat-y), 2) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss / X_set.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1876496745965934"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)= (y_i - \\theta^{T}X_i)*X_i$ \n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)= (y_i - p_i)*X_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X, parameters)\n",
    "        gradient = (y_hat - y) * X[j]\n",
    "    else:\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = - (y - p) * X[j]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07486961672077158"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.18597702631628, 7.231182814101797, 37.3600857876166]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요   \n",
    "총 샘플 수 // batch_size + 1 로 배치의 총 개수를 계산한 이후, batch_size 씩 인덱스를 나워 idx_list에 담아 return이 때,  \n",
    "마지막 배치의 크기 < batch_size일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "    \n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17273176,  0.50129727, -0.00579003])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch:  \n",
    "- num_epoch:\n",
    "<br>\n",
    "\n",
    "BGD: 학습 한 번에 모든 데이터셋을 사용하여 기울기를 업데이트\n",
    "SGD: 학습 한 번에 임의의 1개 데이터만 사용하여 기울기 업데이트 \n",
    "MGD: 학습 한 번에 데이터셋의 일부만 사용하여 기울기 업데이트\n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> SGD\n",
    "batch_size=k -> MGD\n",
    "batch_size=whole ->BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.8131140040179834  params: [-0.03815028  0.30218447  0.07194191]  gradients: [0.04274396347627536, 0.039795324761372014, 0.05378928506109098]\n",
      "epoch: 100  loss: 0.1982175814288324  params: [-1.56202676  3.07285345 -3.020279  ]  gradients: [0.0074069913797305004, 0.01091302493324946, 0.014515902243624207]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.6963365 ,  3.53565051, -3.43445885])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train)\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.3143769275082045  params: [0.48610005 0.66096858 0.19397716]  gradients: [0.005925418137593511, 0.005413217305353089, 0.006826541599413519]\n",
      "epoch: 100  loss: 0.3891403308859842  params: [-0.85395459  0.94949059 -0.94183555]  gradients: [0.0013663358825157308, 0.0014798473198667729, 0.002430161993024417]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.07516123,  1.42558287, -1.41207857])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate=0.01)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.6382163308088985  params: [-0.40568072  0.35746327 -0.07235833]  gradients: [0.11053939102783258, 0.10724813189412423, 0.14753804541286722]\n",
      "epoch: 100  loss: 0.15278119980411708  params: [-1.88474249  4.03010235 -3.95164161]  gradients: [0.021015563163061104, 0.031966446778778086, 0.03822965551470472]\n",
      "epoch: 200  loss: 0.1441946048126026  params: [-1.97123775  4.29672096 -4.19924455]  gradients: [0.020732327372588708, 0.031635639872853887, 0.03694560741922436]\n",
      "epoch: 300  loss: 0.14286689095538918  params: [-1.98551452  4.3405959  -4.23989355]  gradients: [0.020692830157610524, 0.03158554308627181, 0.03674795979042066]\n",
      "epoch: 400  loss: 0.142635926970442  params: [-1.98802483  4.34830697 -4.24703486]  gradients: [0.020686076859176415, 0.031576856575045886, 0.03671360217504817]\n",
      "epoch: 500  loss: 0.14259496702597507  params: [-1.98847085  4.34967695 -4.24830353]  gradients: [0.020684882838764355, 0.03157531694499477, 0.03670750983127169]\n",
      "epoch: 600  loss: 0.14258767840950357  params: [-1.98855025  4.34992081 -4.24852935]  gradients: [0.020684670483509165, 0.03157504300286001, 0.036706425753064334]\n",
      "epoch: 700  loss: 0.14258638065640217  params: [-1.98856439  4.34996423 -4.24856956]  gradients: [0.02068463267685448, 0.031574994227766356, 0.036706232731471]\n",
      "epoch: 800  loss: 0.1425861495640612  params: [-1.9885669   4.34997196 -4.24857672]  gradients: [0.020684625944696652, 0.03157498554235861, 0.036706198359924745]\n",
      "epoch: 900  loss: 0.14258610841240585  params: [-1.98856735  4.34997334 -4.248578  ]  gradients: [0.020684624745874534, 0.03157498399570967, 0.03670619223922919]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.98856743,  4.34997358, -4.24857822])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate=0.3)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 2,  8]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77905783, 2.34487792])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.7509638286682428  params: [0.99477458 1.14479689]  gradients: [-0.019656117709414014, -0.0024063034397704204]\n",
      "epoch: 100  loss: 0.8993242646524782  params: [0.81213225 2.16217854]  gradients: [0.02912950939506979, 0.034696666675592694]\n",
      "epoch: 200  loss: 0.899462933262375  params: [0.81171952 2.16293542]  gradients: [0.02913379536703537, 0.03470524731931194]\n",
      "epoch: 300  loss: 0.8994630546095062  params: [0.81171916 2.16293608]  gradients: [0.02913379911700645, 0.034705254826865865]\n",
      "epoch: 400  loss: 0.8994630547156778  params: [0.81171916 2.16293608]  gradients: [0.029133799120287473, 0.034705254833434555]\n",
      "epoch: 500  loss: 0.899463054715769  params: [0.81171916 2.16293608]  gradients: [0.029133799120290255, 0.03470525483344019]\n",
      "epoch: 600  loss: 0.899463054715769  params: [0.81171916 2.16293608]  gradients: [0.029133799120290255, 0.03470525483344019]\n",
      "epoch: 700  loss: 0.899463054715769  params: [0.81171916 2.16293608]  gradients: [0.029133799120290255, 0.03470525483344019]\n",
      "epoch: 800  loss: 0.899463054715769  params: [0.81171916 2.16293608]  gradients: [0.029133799120290255, 0.03470525483344019]\n",
      "epoch: 900  loss: 0.899463054715769  params: [0.81171916 2.16293608]  gradients: [0.029133799120290255, 0.03470525483344019]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81171916, 2.16293608])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, 0.1, model='linear')\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijgIcAdGLMbA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
